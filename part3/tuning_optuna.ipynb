{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO,DQN\n",
    "from config import config\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import optuna\n",
    "from stable_baselines3.common.callbacks import EvalCallback,BaseCallback\n",
    "\n",
    "log_dir = \"logs\"\n",
    "env_id = \"intersection-v0\"\n",
    "num_cpu = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoneCallback(BaseCallback):\n",
    "    def __init__(self, check_freq: int, save_freq: int, save_path: str, verbose=1):\n",
    "        super(DoneCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_freq = save_freq\n",
    "        self.save_path = save_path\n",
    "        self.done_count = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if 'done' in self.locals.keys():\n",
    "            if self.locals['done']:\n",
    "                self.done_count += 1\n",
    "\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            print(f\"Step: {self.num_timesteps} Done count: {self.done_count}\")\n",
    "\n",
    "        if self.n_calls % self.save_freq == 0:\n",
    "            self.model.save(self.save_path + str(self.num_timesteps))\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_ppo(trial):\n",
    "    \"\"\" Learning hyperparameters we want to optimize\"\"\"\n",
    "    return {\n",
    "        'n_steps': int(trial.suggest_loguniform('n_steps', 32, 2048)),\n",
    "        'gamma': trial.suggest_categorical('gamma', [0.9, 0.95, 0.98, 0.99, 0.999, 0.9999]),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
    "        'ent_coef': trial.suggest_loguniform('ent_coef', 0.00000001, 0.1),\n",
    "        'clip_range': trial.suggest_uniform('clip_range', 0.1, 0.4),\n",
    "        'n_epochs': int(trial.suggest_loguniform('n_epochs', 1, 10)),\n",
    "    }\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\" Objective function for optimization \"\"\"\n",
    "    env = make_vec_env(env_id, n_envs=num_cpu,env_kwargs={\"config\":config})\n",
    "    model = PPO('CnnPolicy', env, verbose=0,tensorboard_log=log_dir,**optimize_ppo(trial))\n",
    "\n",
    "    callback = DoneCallback(check_freq=128, save_freq=5000, save_path=\"./models/hypertuning_\")\n",
    "    eval_env = make_vec_env(env_id, n_envs=1,env_kwargs={\"config\":config})\n",
    "    # Evaulation callback, to evaluate the model during training\n",
    "    eval_callback = EvalCallback(eval_env, best_model_save_path='./logs/',\n",
    "                                 log_path='./logs/', eval_freq=500,\n",
    "                                 deterministic=True, render=False)\n",
    "\n",
    "    model.learn(total_timesteps=512*50, callback=[callback, eval_callback], progress_bar=True)\n",
    "\n",
    "    # Retrieve the best reward\n",
    "    best_reward = eval_callback.best_mean_reward\n",
    "    return best_reward\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "trial = study.best_trial\n",
    "print(trial.value)\n",
    "for key, value in trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a trained model\n",
    "\n",
    "model = DQN.load(\"models/dqn_cnn20000.zip\")\n",
    "eval_env = gym.make(env_id, render_mode=\"rgb_array\", config=config)\n",
    "\n",
    "while True:\n",
    "  done = truncated = False\n",
    "  obs, info = eval_env.reset()\n",
    "  while not (done or truncated):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, truncated, info = eval_env.step(action)\n",
    "    eval_env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
