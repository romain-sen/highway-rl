{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import gymnasium as gym\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "\n",
    "# os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "\n",
    "\n",
    "def eval_agent(agent, env, n_sim=5):\n",
    "    \"\"\"\n",
    "    ** Solution **\n",
    "\n",
    "    Monte Carlo evaluation of DQN agent.\n",
    "\n",
    "    Repeat n_sim times:\n",
    "        * Run the DQN policy until the environment reaches a terminal state (= one episode)\n",
    "        * Compute the sum of rewards in this episode\n",
    "        * Store the sum of rewards in the episode_rewards array.\n",
    "    \"\"\"\n",
    "    env_copy = deepcopy(env)\n",
    "    episode_rewards = np.zeros(n_sim)\n",
    "    for i in range(n_sim):\n",
    "        state, _ = env_copy.reset()\n",
    "        reward_sum = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.get_action(state, 0)\n",
    "            state, reward, terminated, truncated, _ = env_copy.step(action)\n",
    "            reward_sum += reward\n",
    "            done = terminated or truncated\n",
    "        episode_rewards[i] = reward_sum\n",
    "    return episode_rewards\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, reward, terminated, next_state):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = (state, action, reward, terminated, next_state)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.choices(self.memory, k=batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_channels, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # Reduce size to half\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # Reduce size to half again\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2),  # Increased stride\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2),  # Increased stride\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "\n",
    "        # self.convs.add_module(\"Adaptive Pooling\", nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.feature_size = 128  # directly set to 128 assuming you adaptively pooled to (1, 1) and have 128 channels\n",
    "\n",
    "        # Calculate the output size after convolutions\n",
    "        self.feature_size = self._get_conv_output((input_channels, 84, 84))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.feature_size, 256),  # Use calculated feature size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_actions),\n",
    "        )\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        with torch.no_grad():\n",
    "            input = torch.rand(1, *shape)  # simulate input\n",
    "            output = self.convs(input)\n",
    "            total_features = int(\n",
    "                np.prod(output.size()[1:])\n",
    "            )  # product of dimensions excluding the batch size\n",
    "            # print(f\"Calculated feature size for FC layer: {total_features}\")\n",
    "            return total_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
    "        # print(\"x.size() : \", x.size())\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class DQN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        action_space,\n",
    "        observation_space,\n",
    "        gamma,\n",
    "        batch_size,\n",
    "        buffer_capacity,\n",
    "        update_target_every,\n",
    "        epsilon_start,\n",
    "        decrease_epsilon_factor,\n",
    "        epsilon_min,\n",
    "        learning_rate,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.action_space = action_space\n",
    "        self.observation_space = observation_space\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.update_target_every = update_target_every\n",
    "\n",
    "        self.epsilon_start = epsilon_start\n",
    "        self.decrease_epsilon_factor = (\n",
    "            decrease_epsilon_factor  # larger -> more exploration\n",
    "        )\n",
    "        self.epsilon_min = epsilon_min\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def update(self, state, action, reward, terminated, next_state):\n",
    "        \"\"\"\n",
    "        ** SOLUTION **\n",
    "        \"\"\"\n",
    "        # Convert numpy arrays or lists to tensors and ensure they are floats\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        next_state_tensor = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0)\n",
    "        action_tensor = torch.tensor([[action]], dtype=torch.int64)\n",
    "        reward_tensor = torch.tensor([reward], dtype=torch.float32)\n",
    "        terminated_tensor = torch.tensor([terminated], dtype=torch.float32)\n",
    "\n",
    "        # Store transition in the replay buffer\n",
    "        self.buffer.push(\n",
    "            state_tensor,\n",
    "            action_tensor,\n",
    "            reward_tensor,\n",
    "            terminated_tensor,\n",
    "            next_state_tensor,\n",
    "        )\n",
    "\n",
    "        # # add data to replay buffer\n",
    "        # self.buffer.push(\n",
    "        #     torch.tensor(state).unsqueeze(0),\n",
    "        #     torch.tensor([[action]], dtype=torch.int64),\n",
    "        #     torch.tensor([reward]),\n",
    "        #     torch.tensor([terminated], dtype=torch.int64),\n",
    "        #     torch.tensor(next_state, dtype=torch.float).unsqueeze(0),\n",
    "        # )\n",
    "\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return np.inf\n",
    "\n",
    "        # get batch\n",
    "        transitions = self.buffer.sample(self.batch_size)\n",
    "\n",
    "        state_batch, action_batch, reward_batch, terminated_batch, next_state_batch = (\n",
    "            tuple([torch.cat(data) for data in zip(*transitions)])\n",
    "        )\n",
    "\n",
    "        values = self.q_net.forward(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute the ideal Q values\n",
    "        with torch.no_grad():\n",
    "            next_state_values = (1 - terminated_batch) * self.target_net(\n",
    "                next_state_batch\n",
    "            ).max(1)[0]\n",
    "            targets = next_state_values * self.gamma + reward_batch\n",
    "\n",
    "        loss = self.loss_function(values, targets.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model with gradient clipping\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.q_net.parameters(), 1)  # Gradient clipping\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Soft update the target network\n",
    "        for target_param, local_param in zip(\n",
    "            self.target_net.parameters(), self.q_net.parameters()\n",
    "        ):\n",
    "            target_param.data.copy_(\n",
    "                0.995 * target_param.data + 0.005 * local_param.data\n",
    "            )\n",
    "\n",
    "        self.scheduler.step()  # Step through the scheduler\n",
    "\n",
    "        if not ((self.n_steps + 1) % self.update_target_every):\n",
    "            self.target_net.load_state_dict(self.q_net.state_dict())\n",
    "\n",
    "        self.decrease_epsilon()\n",
    "\n",
    "        self.n_steps += 1\n",
    "        if terminated:\n",
    "            self.n_eps += 1\n",
    "\n",
    "        return loss.detach().numpy()\n",
    "\n",
    "    def get_action(self, state, epsilon=None):\n",
    "        \"\"\"\n",
    "        Return action according to an epsilon-greedy exploration policy\n",
    "        \"\"\"\n",
    "        if epsilon is None:\n",
    "            epsilon = self.epsilon\n",
    "\n",
    "        if np.random.rand() < epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            return np.argmax(self.get_q(state))\n",
    "\n",
    "    def get_q(self, state):\n",
    "        \"\"\"\n",
    "        Compute Q function for a states\n",
    "        \"\"\"\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = self.q_net.forward(state_tensor)  # shape (1,  n_actions)\n",
    "        return output.numpy()[0]  # shape  (n_actions)\n",
    "\n",
    "    def decrease_epsilon(self):\n",
    "        self.epsilon = self.epsilon_min + (self.epsilon_start - self.epsilon_min) * (\n",
    "            np.exp(-1.0 * self.n_eps / self.decrease_epsilon_factor)\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        input_channels = self.observation_space.shape[\n",
    "            0\n",
    "        ]  # Assuming observation space is image-based\n",
    "        n_actions = self.action_space.n\n",
    "\n",
    "        self.buffer = ReplayBuffer(self.buffer_capacity)\n",
    "        self.q_net = Net(input_channels, n_actions)\n",
    "        self.target_net = Net(input_channels, n_actions)\n",
    "        self.target_net.load_state_dict(\n",
    "            self.q_net.state_dict()\n",
    "        )  # Initialize target net\n",
    "        self.target_net.eval()  # Set target net to eval mode\n",
    "\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(\n",
    "            params=self.q_net.parameters(), lr=self.learning_rate, weight_decay=1e-5\n",
    "        )\n",
    "        self.scheduler = StepLR(\n",
    "            self.optimizer, step_size=100, gamma=0.99\n",
    "        )  # Learning rate scheduler\n",
    "\n",
    "        self.epsilon = self.epsilon_start\n",
    "        self.n_steps = 0\n",
    "        self.n_eps = 0\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"\n",
    "        Save the current model parameters to the specified file.\n",
    "        \"\"\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"q_net_state_dict\": self.q_net.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": self.scheduler.state_dict(),\n",
    "                \"epsilon\": self.epsilon,\n",
    "                \"n_steps\": self.n_steps,\n",
    "                \"n_eps\": self.n_eps,\n",
    "            },\n",
    "            filename,\n",
    "        )\n",
    "        print(f\"Model saved to {filename}\")\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\"\n",
    "        Load model parameters from the specified file.\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.q_net.load_state_dict(checkpoint[\"q_net_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        self.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        self.epsilon = checkpoint[\"epsilon\"]\n",
    "        self.n_steps = checkpoint[\"n_steps\"]\n",
    "        self.n_eps = checkpoint[\"n_eps\"]\n",
    "        self.target_net.load_state_dict(self.q_net.state_dict())\n",
    "        print(f\"Model loaded from {filename}\")\n",
    "\n",
    "\n",
    "def run_one_episode(env, agent, display=True):\n",
    "    display_env = deepcopy(env)\n",
    "    done = False\n",
    "    state, _ = display_env.reset()\n",
    "\n",
    "    rewards = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.get_action(state, 0)\n",
    "        state, reward, done, _, _ = display_env.step(action)\n",
    "        rewards += reward\n",
    "        if display:\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow(display_env.render())\n",
    "            plt.show()\n",
    "    if display:\n",
    "        display_env.close()\n",
    "    print(f\"Episode length {rewards}\")\n",
    "\n",
    "\n",
    "def run_episodes_for_a_minute(env, agent, display=True):\n",
    "    start_time = time.time()\n",
    "    episodes = 0\n",
    "    total_rewards = 0\n",
    "\n",
    "    while time.time() - start_time < 10:  # Exécuter pendant environ une minute\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        episode_rewards = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.get_action(state, 0)\n",
    "            state, reward, done, _, _ = env.step(action)\n",
    "            episode_rewards += reward\n",
    "            if display:\n",
    "                # clear_output(wait=True)\n",
    "                # plt.imshow(env.render())\n",
    "                # plt.show()\n",
    "                env.render()\n",
    "\n",
    "        episodes += 1\n",
    "        total_rewards += episode_rewards\n",
    "        print(f\"Episode {episodes} reward: {episode_rewards}\")\n",
    "\n",
    "    print(f\"Nombre total d'épisodes exécutés en 1 minute : {episodes}\")\n",
    "    print(f\"Récompense moyenne sur les épisodes : {total_rewards / episodes}\")\n",
    "\n",
    "\n",
    "# env = env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "# agent = RandomAgent(env.observation_space, env.action_space)\n",
    "\n",
    "# # Exécuter la fonction pour des épisodes répétés pendant environ une minute\n",
    "# run_episodes_for_a_minute(env, agent)\n",
    "\n",
    "# # run_one_episode(env, agent, display=True)\n",
    "# print(f\"Average over 5 runs : {np.mean(eval_agent(agent, env))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, agent, N_episodes, eval_every=10, reward_threshold=300):\n",
    "    total_time = 0\n",
    "    state, _ = env.reset()\n",
    "    losses = []\n",
    "    for ep in range(N_episodes):\n",
    "        done = False\n",
    "        state, _ = env.reset()\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            loss_val = agent.update(state, action, reward, terminated, next_state)\n",
    "\n",
    "            state = next_state\n",
    "            losses.append(loss_val)\n",
    "\n",
    "            done = terminated or truncated\n",
    "            total_time += 1\n",
    "\n",
    "        if (ep + 1) % eval_every == 0:\n",
    "            rewards = eval_agent(agent, env)\n",
    "            print(\"episode =\", ep + 1, \", reward = \", np.mean(rewards))\n",
    "            if np.mean(rewards) >= reward_threshold:\n",
    "                break\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode = 10 , reward =  5.239034265258679\n",
      "episode = 20 , reward =  11.67119165076281\n",
      "episode = 30 , reward =  9.95625\n",
      "episode = 40 , reward =  8.9375\n",
      "episode = 50 , reward =  6.825\n",
      "episode = 60 , reward =  5.55625\n",
      "episode = 70 , reward =  8.8625\n",
      "episode = 80 , reward =  5.04375\n",
      "episode = 90 , reward =  7.923862958010746\n",
      "episode = 100 , reward =  4.513400797742806\n",
      "episode = 110 , reward =  6.246636165748692\n",
      "episode = 120 , reward =  9.546191650762811\n",
      "episode = 130 , reward =  3.674073156858978\n",
      "episode = 140 , reward =  6.825\n",
      "episode = 150 , reward =  5.0625\n",
      "episode = 160 , reward =  8.684136165748692\n",
      "episode = 170 , reward =  10.0625\n",
      "episode = 180 , reward =  2.9375\n",
      "episode = 190 , reward =  9.121636165748692\n",
      "episode = 200 , reward =  10.5\n",
      "episode = 210 , reward =  2.516825398871403\n",
      "episode = 220 , reward =  8.986362958010746\n",
      "episode = 230 , reward =  7.112698611634713\n",
      "episode = 240 , reward =  3.7625\n",
      "episode = 250 , reward =  6.861362958010747\n",
      "episode = 260 , reward =  5.825\n",
      "episode = 270 , reward =  11.375\n",
      "episode = 280 , reward =  10.0625\n",
      "episode = 290 , reward =  11.375\n",
      "episode = 300 , reward =  7.0875\n",
      "episode = 310 , reward =  7.6725273043867785\n",
      "episode = 320 , reward =  6.809136165748692\n",
      "episode = 330 , reward =  9.797527304386778\n",
      "episode = 340 , reward =  4.729975398871403\n",
      "episode = 350 , reward =  2.6285753988714027\n",
      "episode = 360 , reward =  8.5875\n",
      "episode = 370 , reward =  8.246636165748692\n",
      "episode = 380 , reward =  4.809136165748692\n",
      "episode = 390 , reward =  5.184136165748692\n",
      "episode = 400 , reward =  1.8316299999999999\n",
      "episode = 410 , reward =  9.797527304386778\n",
      "episode = 420 , reward =  11.8125\n",
      "episode = 430 , reward =  3.2\n",
      "episode = 440 , reward =  4.78125\n",
      "episode = 450 , reward =  7.6725273043867785\n",
      "episode = 460 , reward =  8.225\n",
      "episode = 470 , reward =  2.7207627977428053\n",
      "episode = 480 , reward =  2.6655268642958916\n",
      "episode = 490 , reward =  5.7625\n",
      "episode = 500 , reward =  5.246636165748692\n",
      "episode = 510 , reward =  2.771308161075745\n",
      "episode = 520 , reward =  10.5625\n",
      "episode = 530 , reward =  8.173862958010744\n",
      "episode = 540 , reward =  11.8125\n",
      "episode = 550 , reward =  2.45625\n",
      "episode = 560 , reward =  9.3875\n",
      "episode = 570 , reward =  10.610027304386778\n",
      "episode = 580 , reward =  10.0625\n",
      "episode = 590 , reward =  2.51875\n",
      "episode = 600 , reward =  4.3875\n",
      "episode = 610 , reward =  3.024322682965077\n",
      "episode = 620 , reward =  3.8702111176154608\n",
      "episode = 630 , reward =  7.425\n",
      "episode = 640 , reward =  12.6375\n",
      "episode = 650 , reward =  2.1598253988714027\n",
      "episode = 660 , reward =  1.6848253988714028\n",
      "episode = 670 , reward =  9.54375\n",
      "episode = 680 , reward =  5.04375\n",
      "episode = 690 , reward =  5.1125\n",
      "episode = 700 , reward =  4.8625\n",
      "episode = 710 , reward =  2.9875\n",
      "episode = 720 , reward =  4.6604588056685845\n",
      "episode = 730 , reward =  10.0625\n",
      "episode = 740 , reward =  2.1875\n",
      "episode = 750 , reward =  6.73125\n",
      "episode = 760 , reward =  10.9375\n",
      "episode = 770 , reward =  3.465097255888831\n",
      "episode = 780 , reward =  7.75\n",
      "episode = 790 , reward =  9.764356968515088\n",
      "episode = 800 , reward =  10.9375\n",
      "episode = 810 , reward =  6.16875\n",
      "episode = 820 , reward =  12.28125\n",
      "episode = 830 , reward =  11.375\n",
      "episode = 840 , reward =  4.524423307019026\n",
      "episode = 850 , reward =  10.517897617104225\n",
      "episode = 860 , reward =  10.5\n",
      "episode = 870 , reward =  7.065957461012211\n",
      "episode = 880 , reward =  10.0625\n",
      "episode = 890 , reward =  10.0625\n",
      "episode = 900 , reward =  9.28125\n",
      "episode = 910 , reward =  11.0625\n",
      "episode = 920 , reward =  11.375\n",
      "episode = 930 , reward =  9.625\n",
      "episode = 940 , reward =  10.2625\n",
      "episode = 950 , reward =  9.0625\n",
      "episode = 960 , reward =  10.0625\n",
      "episode = 970 , reward =  9.53125\n",
      "episode = 980 , reward =  10.0625\n",
      "episode = 990 , reward =  11.8125\n",
      "episode = 1000 , reward =  9.625\n",
      "Model saved to dqn_agent_2_1000.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d24a5640>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjusted environment initialization for \"highway-fast-v0\"\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from config import config\n",
    "\n",
    "# Configure and create the environment\n",
    "env = gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\", config=config)\n",
    "action_space = env.action_space\n",
    "observation_space = env.observation_space\n",
    "\n",
    "# Update the DQN Agent initialization with the new action and observation spaces\n",
    "# Note: Ensure that observation dimensions are correctly handled within your DQN architecture.\n",
    "# This might require adjustments depending on how the \"OccupancyGrid\" observations are structured.\n",
    "\n",
    "# Hyperparameters might need adjustment based on the new environment dynamics.\n",
    "gamma = 0.99\n",
    "batch_size = 128\n",
    "buffer_capacity = 20_000\n",
    "update_target_every = 32\n",
    "epsilon_start = 0.9\n",
    "decrease_epsilon_factor = 1500\n",
    "epsilon_min = 0.01\n",
    "learning_rate = 1e-3\n",
    "\n",
    "hidden_size = 256\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# When you instantiate the DQN agent:\n",
    "agent = DQN(\n",
    "    env,\n",
    "    action_space,\n",
    "    observation_space,\n",
    "    gamma,\n",
    "    batch_size,\n",
    "    buffer_capacity,\n",
    "    update_target_every,\n",
    "    epsilon_start,\n",
    "    decrease_epsilon_factor,\n",
    "    epsilon_min,\n",
    "    learning_rate,\n",
    ")\n",
    "\n",
    "# Training might need adjustments, especially evaluation metrics and thresholding for success.\n",
    "N_episodes = 1000\n",
    "\n",
    "# Proceed with the adjusted training function\n",
    "# Ensure that your training and evaluation routines properly handle the updated environment observations and actions.\n",
    "losses = train(env, agent, N_episodes)\n",
    "agent.save(\"dqn_agent_2_1000.pth\")\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated feature size for FC layer: 4608\n",
      "Calculated feature size for FC layer: 4608\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Net:\n\tMissing key(s) in state_dict: \"convs.0.weight\", \"convs.0.bias\", \"convs.3.weight\", \"convs.3.bias\", \"convs.6.weight\", \"convs.6.bias\", \"convs.8.weight\", \"convs.8.bias\", \"fc.0.weight\", \"fc.0.bias\", \"fc.2.weight\", \"fc.2.bias\". \n\tUnexpected key(s) in state_dict: \"net.0.weight\", \"net.0.bias\", \"net.2.weight\", \"net.2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 42\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# When you instantiate the DQN agent:\u001b[39;00m\n\u001b[1;32m     28\u001b[0m agent \u001b[38;5;241m=\u001b[39m DQN(\n\u001b[1;32m     29\u001b[0m     env,\n\u001b[1;32m     30\u001b[0m     action_space,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     learning_rate,\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 42\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdqn_agent_3000.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 295\u001b[0m, in \u001b[0;36mDQN.load\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03mLoad model parameters from the specified file.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(filename)\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq_net_state_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Centrale/RL/highway-rl/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Net:\n\tMissing key(s) in state_dict: \"convs.0.weight\", \"convs.0.bias\", \"convs.3.weight\", \"convs.3.bias\", \"convs.6.weight\", \"convs.6.bias\", \"convs.8.weight\", \"convs.8.bias\", \"fc.0.weight\", \"fc.0.bias\", \"fc.2.weight\", \"fc.2.bias\". \n\tUnexpected key(s) in state_dict: \"net.0.weight\", \"net.0.bias\", \"net.2.weight\", \"net.2.bias\". "
     ]
    }
   ],
   "source": [
    "# Load the trained agent\n",
    "from config import config\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "env = gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\", config=config)\n",
    "action_space = env.action_space\n",
    "observation_space = env.observation_space\n",
    "\n",
    "# Update the DQN Agent initialization with the new action and observation spaces\n",
    "# Note: Ensure that observation dimensions are correctly handled within your DQN architecture.\n",
    "# This might require adjustments depending on how the \"OccupancyGrid\" observations are structured.\n",
    "\n",
    "# Hyperparameters might need adjustment based on the new environment dynamics.\n",
    "gamma = 0.99\n",
    "batch_size = 128\n",
    "buffer_capacity = 20_000\n",
    "update_target_every = 32\n",
    "epsilon_start = 0.9\n",
    "decrease_epsilon_factor = 1500\n",
    "epsilon_min = 0.01\n",
    "learning_rate = 1e-4\n",
    "\n",
    "hidden_size = 256\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# When you instantiate the DQN agent:\n",
    "agent = DQN(\n",
    "    env,\n",
    "    action_space,\n",
    "    observation_space,\n",
    "    gamma,\n",
    "    batch_size,\n",
    "    buffer_capacity,\n",
    "    update_target_every,\n",
    "    epsilon_start,\n",
    "    decrease_epsilon_factor,\n",
    "    epsilon_min,\n",
    "    learning_rate,\n",
    ")\n",
    "\n",
    "agent.load(\"dqn_agent_3000.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean reward after training =  10.828125\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final policy\n",
    "rewards = eval_agent(agent, env, 20)\n",
    "print(\"\")\n",
    "print(\"mean reward after training = \", np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# env = gym.make('highway-v0', render_mode='rgb_array')\n",
    "state = env.reset()\n",
    "for _ in range(1):\n",
    "    state = env.reset()\n",
    "    # action = env.action_type.actions_indexes[\"IDLE\"]\n",
    "    # print(state)\n",
    "    action = agent.get_action(state)\n",
    "    # print(action)\n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "plt.imshow(env.render())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zk/rcqnm5cj1s31mwy0myzr5df00000gp/T/ipykernel_52822/736564058.py:242: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  state_tensor = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 7 at dim 1 (got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (done \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[0;32m----> 5\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m      7\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n",
      "Cell \u001b[0;32mIn[56], line 236\u001b[0m, in \u001b[0;36mDQN.get_action\u001b[0;34m(self, state, epsilon)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[56], line 242\u001b[0m, in \u001b[0;36mDQN.get_q\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_q\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m    239\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    Compute Q function for a states\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    244\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net\u001b[38;5;241m.\u001b[39mforward(state_tensor)  \u001b[38;5;66;03m# shape (1,  n_actions)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 7 at dim 1 (got 4)"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    done = truncated = False\n",
    "    obs = env.reset()\n",
    "    while not (done or truncated):\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
