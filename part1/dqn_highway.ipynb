{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import gymnasium as gym\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "\n",
    "# os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "\n",
    "\n",
    "def eval_agent(agent, env, n_sim=5):\n",
    "    \"\"\"\n",
    "    ** Solution **\n",
    "\n",
    "    Monte Carlo evaluation of DQN agent.\n",
    "\n",
    "    Repeat n_sim times:\n",
    "        * Run the DQN policy until the environment reaches a terminal state (= one episode)\n",
    "        * Compute the sum of rewards in this episode\n",
    "        * Store the sum of rewards in the episode_rewards array.\n",
    "    \"\"\"\n",
    "    env_copy = deepcopy(env)\n",
    "    episode_rewards = np.zeros(n_sim)\n",
    "    for i in range(n_sim):\n",
    "        state, _ = env_copy.reset()\n",
    "        reward_sum = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.get_action(state, 0)\n",
    "            state, reward, terminated, truncated, _ = env_copy.step(action)\n",
    "            reward_sum += reward\n",
    "            done = terminated or truncated\n",
    "        episode_rewards[i] = reward_sum\n",
    "    return episode_rewards\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, reward, terminated, next_state):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = (state, action, reward, terminated, next_state)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.choices(self.memory, k=batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic neural net.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return self.net(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class DQN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        action_space,\n",
    "        observation_space,\n",
    "        gamma,\n",
    "        batch_size,\n",
    "        buffer_capacity,\n",
    "        update_target_every,\n",
    "        epsilon_start,\n",
    "        decrease_epsilon_factor,\n",
    "        epsilon_min,\n",
    "        learning_rate,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.action_space = action_space\n",
    "        self.observation_space = observation_space\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.update_target_every = update_target_every\n",
    "\n",
    "        self.epsilon_start = epsilon_start\n",
    "        self.decrease_epsilon_factor = (\n",
    "            decrease_epsilon_factor  # larger -> more exploration\n",
    "        )\n",
    "        self.epsilon_min = epsilon_min\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def update(self, state, action, reward, terminated, next_state):\n",
    "        \"\"\"\n",
    "        ** SOLUTION **\n",
    "        \"\"\"\n",
    "        # Convert numpy arrays or lists to tensors and ensure they are floats\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        next_state_tensor = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0)\n",
    "        action_tensor = torch.tensor([[action]], dtype=torch.int64)\n",
    "        reward_tensor = torch.tensor([reward], dtype=torch.float32)\n",
    "        terminated_tensor = torch.tensor([terminated], dtype=torch.float32)\n",
    "\n",
    "        # Store transition in the replay buffer\n",
    "        self.buffer.push(\n",
    "            state_tensor,\n",
    "            action_tensor,\n",
    "            reward_tensor,\n",
    "            terminated_tensor,\n",
    "            next_state_tensor,\n",
    "        )\n",
    "\n",
    "        # # add data to replay buffer\n",
    "        # self.buffer.push(\n",
    "        #     torch.tensor(state).unsqueeze(0),\n",
    "        #     torch.tensor([[action]], dtype=torch.int64),\n",
    "        #     torch.tensor([reward]),\n",
    "        #     torch.tensor([terminated], dtype=torch.int64),\n",
    "        #     torch.tensor(next_state, dtype=torch.float).unsqueeze(0),\n",
    "        # )\n",
    "\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return np.inf\n",
    "\n",
    "        # get batch\n",
    "        transitions = self.buffer.sample(self.batch_size)\n",
    "\n",
    "        state_batch, action_batch, reward_batch, terminated_batch, next_state_batch = (\n",
    "            tuple([torch.cat(data) for data in zip(*transitions)])\n",
    "        )\n",
    "\n",
    "        values = self.q_net.forward(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute the ideal Q values\n",
    "        with torch.no_grad():\n",
    "            next_state_values = (1 - terminated_batch) * self.target_net(\n",
    "                next_state_batch\n",
    "            ).max(1)[0]\n",
    "            targets = next_state_values * self.gamma + reward_batch\n",
    "\n",
    "        loss = self.loss_function(values, targets.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model with gradient clipping\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.q_net.parameters(), 1)  # Gradient clipping\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Soft update the target network\n",
    "        for target_param, local_param in zip(\n",
    "            self.target_net.parameters(), self.q_net.parameters()\n",
    "        ):\n",
    "            target_param.data.copy_(\n",
    "                0.995 * target_param.data + 0.005 * local_param.data\n",
    "            )\n",
    "\n",
    "        self.scheduler.step()  # Step through the scheduler\n",
    "\n",
    "        if not ((self.n_steps + 1) % self.update_target_every):\n",
    "            self.target_net.load_state_dict(self.q_net.state_dict())\n",
    "\n",
    "        self.decrease_epsilon()\n",
    "\n",
    "        self.n_steps += 1\n",
    "        if terminated:\n",
    "            self.n_eps += 1\n",
    "\n",
    "        return loss.detach().numpy()\n",
    "\n",
    "    def get_action(self, state, epsilon=None):\n",
    "        \"\"\"\n",
    "        Return action according to an epsilon-greedy exploration policy\n",
    "        \"\"\"\n",
    "        if epsilon is None:\n",
    "            epsilon = self.epsilon\n",
    "\n",
    "        if np.random.rand() < epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            return np.argmax(self.get_q(state))\n",
    "\n",
    "    def get_q(self, state):\n",
    "        \"\"\"\n",
    "        Compute Q function for a states\n",
    "        \"\"\"\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = self.q_net.forward(state_tensor)  # shape (1,  n_actions)\n",
    "        return output.numpy()[0]  # shape  (n_actions)\n",
    "\n",
    "    def decrease_epsilon(self):\n",
    "        self.epsilon = self.epsilon_min + (self.epsilon_start - self.epsilon_min) * (\n",
    "            np.exp(-1.0 * self.n_eps / self.decrease_epsilon_factor)\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        hidden_size = 256\n",
    "\n",
    "        # obs_size = self.observation_space.shape[0]\n",
    "        obs_size = np.prod(self.env.observation_space.shape)\n",
    "        n_actions = self.action_space.n\n",
    "\n",
    "        self.buffer = ReplayBuffer(self.buffer_capacity)\n",
    "        self.q_net = Net(obs_size, hidden_size, n_actions)\n",
    "        self.target_net = Net(obs_size, hidden_size, n_actions)\n",
    "        self.target_net.load_state_dict(\n",
    "            self.q_net.state_dict()\n",
    "        )  # Initialize target net\n",
    "        self.target_net.eval()  # Set target net to eval mode\n",
    "\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(\n",
    "            params=self.q_net.parameters(), lr=self.learning_rate, weight_decay=1e-5\n",
    "        )\n",
    "        self.scheduler = StepLR(\n",
    "            self.optimizer, step_size=100, gamma=0.99\n",
    "        )  # Learning rate scheduler\n",
    "\n",
    "        self.epsilon = self.epsilon_start\n",
    "        self.n_steps = 0\n",
    "        self.n_eps = 0\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"\n",
    "        Save the current model parameters to the specified file.\n",
    "        \"\"\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"q_net_state_dict\": self.q_net.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": self.scheduler.state_dict(),\n",
    "                \"epsilon\": self.epsilon,\n",
    "                \"n_steps\": self.n_steps,\n",
    "                \"n_eps\": self.n_eps,\n",
    "            },\n",
    "            filename,\n",
    "        )\n",
    "        print(f\"Model saved to {filename}\")\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\"\n",
    "        Load model parameters from the specified file.\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.q_net.load_state_dict(checkpoint[\"q_net_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        self.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        self.epsilon = checkpoint[\"epsilon\"]\n",
    "        self.n_steps = checkpoint[\"n_steps\"]\n",
    "        self.n_eps = checkpoint[\"n_eps\"]\n",
    "        self.target_net.load_state_dict(self.q_net.state_dict())\n",
    "        print(f\"Model loaded from {filename}\")\n",
    "\n",
    "\n",
    "def run_one_episode(env, agent, display=True):\n",
    "    display_env = deepcopy(env)\n",
    "    done = False\n",
    "    state, _ = display_env.reset()\n",
    "\n",
    "    rewards = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.get_action(state, 0)\n",
    "        state, reward, done, _, _ = display_env.step(action)\n",
    "        rewards += reward\n",
    "        if display:\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow(display_env.render())\n",
    "            plt.show()\n",
    "    if display:\n",
    "        display_env.close()\n",
    "    print(f\"Episode length {rewards}\")\n",
    "\n",
    "\n",
    "def run_episodes_for_a_minute(env, agent, display=True):\n",
    "    start_time = time.time()\n",
    "    episodes = 0\n",
    "    total_rewards = 0\n",
    "\n",
    "    while time.time() - start_time < 10:  # Exécuter pendant environ une minute\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        episode_rewards = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.get_action(state, 0)\n",
    "            state, reward, done, _, _ = env.step(action)\n",
    "            episode_rewards += reward\n",
    "            if display:\n",
    "                # clear_output(wait=True)\n",
    "                # plt.imshow(env.render())\n",
    "                # plt.show()\n",
    "                env.render()\n",
    "\n",
    "        episodes += 1\n",
    "        total_rewards += episode_rewards\n",
    "        print(f\"Episode {episodes} reward: {episode_rewards}\")\n",
    "\n",
    "    print(f\"Nombre total d'épisodes exécutés en 1 minute : {episodes}\")\n",
    "    print(f\"Récompense moyenne sur les épisodes : {total_rewards / episodes}\")\n",
    "\n",
    "\n",
    "# env = env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "# agent = RandomAgent(env.observation_space, env.action_space)\n",
    "\n",
    "# # Exécuter la fonction pour des épisodes répétés pendant environ une minute\n",
    "# run_episodes_for_a_minute(env, agent)\n",
    "\n",
    "# # run_one_episode(env, agent, display=True)\n",
    "# print(f\"Average over 5 runs : {np.mean(eval_agent(agent, env))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, agent, N_episodes, eval_every=10, reward_threshold=300):\n",
    "    total_time = 0\n",
    "    state, _ = env.reset()\n",
    "    losses = []\n",
    "    for ep in range(N_episodes):\n",
    "        done = False\n",
    "        state, _ = env.reset()\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            loss_val = agent.update(state, action, reward, terminated, next_state)\n",
    "\n",
    "            state = next_state\n",
    "            losses.append(loss_val)\n",
    "\n",
    "            done = terminated or truncated\n",
    "            total_time += 1\n",
    "\n",
    "        if (ep + 1) % eval_every == 0:\n",
    "            rewards = eval_agent(agent, env)\n",
    "            print(\"episode =\", ep + 1, \", reward = \", np.mean(rewards))\n",
    "            if np.mean(rewards) >= reward_threshold:\n",
    "                break\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode = 10 , reward =  9.2875\n",
      "episode = 20 , reward =  5.7625\n",
      "episode = 30 , reward =  10.99375\n",
      "episode = 40 , reward =  9.84375\n",
      "episode = 50 , reward =  13.475\n",
      "episode = 60 , reward =  14.48125\n",
      "episode = 70 , reward =  14.44375\n",
      "episode = 80 , reward =  14.84375\n",
      "episode = 90 , reward =  12.125\n",
      "episode = 100 , reward =  9.625\n",
      "episode = 110 , reward =  10.0625\n",
      "episode = 120 , reward =  10.9375\n",
      "episode = 130 , reward =  11.375\n",
      "episode = 140 , reward =  10.9375\n",
      "episode = 150 , reward =  10.5\n",
      "episode = 160 , reward =  12.25\n",
      "episode = 170 , reward =  9.625\n",
      "episode = 180 , reward =  10.5\n",
      "episode = 190 , reward =  9.625\n",
      "episode = 200 , reward =  10.9375\n",
      "episode = 210 , reward =  10.5\n",
      "episode = 220 , reward =  11.8125\n",
      "episode = 230 , reward =  11.375\n",
      "episode = 240 , reward =  11.09375\n",
      "episode = 250 , reward =  10.9375\n",
      "episode = 260 , reward =  11.8125\n",
      "episode = 270 , reward =  16.93125\n",
      "episode = 280 , reward =  14.08125\n",
      "episode = 290 , reward =  11.8125\n",
      "episode = 300 , reward =  12.23125\n",
      "episode = 310 , reward =  12.25\n",
      "episode = 320 , reward =  16.91875\n",
      "episode = 330 , reward =  11.55\n",
      "episode = 340 , reward =  10.9375\n",
      "episode = 350 , reward =  15.04375\n",
      "episode = 360 , reward =  15.6875\n",
      "episode = 370 , reward =  16.29375\n",
      "episode = 380 , reward =  11.97575\n",
      "episode = 390 , reward =  12.44375\n",
      "episode = 400 , reward =  12.88125\n",
      "episode = 410 , reward =  10.6125\n",
      "episode = 420 , reward =  16.39375\n",
      "episode = 430 , reward =  10.625\n",
      "episode = 440 , reward =  13.16190159829431\n",
      "episode = 450 , reward =  15.675\n",
      "episode = 460 , reward =  13.68125\n",
      "episode = 470 , reward =  15.675\n",
      "episode = 480 , reward =  14.624401598294309\n",
      "episode = 490 , reward =  11.93125\n",
      "episode = 500 , reward =  13.8375\n",
      "episode = 510 , reward =  17.6125\n",
      "episode = 520 , reward =  7.536303196588617\n",
      "episode = 530 , reward =  16.28125\n",
      "episode = 540 , reward =  10.0875\n",
      "episode = 550 , reward =  16.36875\n",
      "episode = 560 , reward =  12.966075398871402\n",
      "episode = 570 , reward =  15.66875\n",
      "episode = 580 , reward =  14.205000000000002\n",
      "episode = 590 , reward =  12.9625\n",
      "episode = 600 , reward =  16.90625\n",
      "episode = 610 , reward =  12.10625\n",
      "episode = 620 , reward =  12.93125\n",
      "episode = 630 , reward =  14.8625\n",
      "episode = 640 , reward =  10.33125\n",
      "episode = 650 , reward =  17.59375\n",
      "episode = 660 , reward =  14.475\n",
      "episode = 670 , reward =  16.375\n",
      "episode = 680 , reward =  15.74375\n",
      "episode = 690 , reward =  13.88125\n",
      "episode = 700 , reward =  15.2\n",
      "episode = 710 , reward =  12.25\n",
      "episode = 720 , reward =  14.8125\n",
      "episode = 730 , reward =  12.318151598294309\n",
      "episode = 740 , reward =  15.675\n",
      "episode = 750 , reward =  15.7125\n",
      "episode = 760 , reward =  13.01875\n",
      "episode = 770 , reward =  11.2\n",
      "episode = 780 , reward =  16.0875\n",
      "episode = 790 , reward =  16.94375\n",
      "episode = 800 , reward =  13.8125\n",
      "episode = 810 , reward =  13.175\n",
      "episode = 820 , reward =  10.7625\n",
      "episode = 830 , reward =  15.125\n",
      "episode = 840 , reward =  12.28125\n",
      "episode = 850 , reward =  12.45375\n",
      "episode = 860 , reward =  16.375\n",
      "episode = 870 , reward =  13.39375\n",
      "episode = 880 , reward =  13.81815159829431\n",
      "episode = 890 , reward =  13.35625\n",
      "episode = 900 , reward =  17.01875\n",
      "episode = 910 , reward =  13.56875\n",
      "episode = 920 , reward =  14.778\n",
      "episode = 930 , reward =  12.81875\n",
      "episode = 940 , reward =  15.68125\n",
      "episode = 950 , reward =  11.8125\n",
      "episode = 960 , reward =  15.7125\n",
      "episode = 970 , reward =  16.29375\n",
      "episode = 980 , reward =  10.525\n",
      "episode = 990 , reward =  11.49375\n",
      "episode = 1000 , reward =  13.44940159829431\n",
      "Model saved to dqn_agent.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2e1774310>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjusted environment initialization for \"highway-fast-v0\"\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from config import config\n",
    "\n",
    "# Configure and create the environment\n",
    "env = gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\", config=config)\n",
    "action_space = env.action_space\n",
    "observation_space = env.observation_space\n",
    "\n",
    "# Update the DQN Agent initialization with the new action and observation spaces\n",
    "# Note: Ensure that observation dimensions are correctly handled within your DQN architecture.\n",
    "# This might require adjustments depending on how the \"OccupancyGrid\" observations are structured.\n",
    "\n",
    "# Hyperparameters might need adjustment based on the new environment dynamics.\n",
    "gamma = 0.99\n",
    "batch_size = 128\n",
    "buffer_capacity = 20_000\n",
    "update_target_every = 32\n",
    "epsilon_start = 0.9\n",
    "decrease_epsilon_factor = 1500\n",
    "epsilon_min = 0.01\n",
    "learning_rate = 1e-4\n",
    "\n",
    "hidden_size = 256\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# When you instantiate the DQN agent:\n",
    "agent = DQN(\n",
    "    env,\n",
    "    action_space,\n",
    "    observation_space,\n",
    "    gamma,\n",
    "    batch_size,\n",
    "    buffer_capacity,\n",
    "    update_target_every,\n",
    "    epsilon_start,\n",
    "    decrease_epsilon_factor,\n",
    "    epsilon_min,\n",
    "    learning_rate,\n",
    ")\n",
    "\n",
    "# Training might need adjustments, especially evaluation metrics and thresholding for success.\n",
    "N_episodes = 1000\n",
    "\n",
    "# Proceed with the adjusted training function\n",
    "# Ensure that your training and evaluation routines properly handle the updated environment observations and actions.\n",
    "losses = train(env, agent, N_episodes)\n",
    "agent.save(\"dqn_agent.pth\")\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained agent\n",
    "agent = DQN(env, action_space, observation_space, gamma, batch_size, buffer_capacity, update_target_every, epsilon_start, decrease_epsilon_factor, epsilon_min, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the final policy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rewards \u001b[38;5;241m=\u001b[39m \u001b[43meval_agent\u001b[49m(agent, env, \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean reward after training = \u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(rewards))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_agent' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the final policy\n",
    "rewards = eval_agent(agent, env, 20)\n",
    "print(\"\")\n",
    "print(\"mean reward after training = \", np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), {'speed': 25, 'crashed': False, 'action': 4, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.5, 'high_speed_reward': 0.5, 'on_road_reward': 1.0}})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# env = gym.make('highway-v0', render_mode='rgb_array')\n",
    "state = env.reset()\n",
    "for _ in range(1):\n",
    "    state = env.reset()\n",
    "    # action = env.action_type.actions_indexes[\"IDLE\"]\n",
    "    print(state)\n",
    "    action = agent.get_action(state)\n",
    "    # print(action)\n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "plt.imshow(env.render())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
