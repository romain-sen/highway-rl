{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import gymnasium as gym\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "\n",
    "# os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "\n",
    "\n",
    "def eval_agent(agent, env, n_sim=5):\n",
    "    \"\"\"\n",
    "    Monte Carlo evaluation of DQN agent.\n",
    "\n",
    "    Repeat n_sim times:\n",
    "        * Run the DQN policy until the environment reaches a terminal state (= one episode)\n",
    "        * Compute the sum of rewards in this episode\n",
    "        * Store the sum of rewards in the episode_rewards array.\n",
    "    \"\"\"\n",
    "    env_copy = deepcopy(env)\n",
    "    episode_rewards = np.zeros(n_sim)\n",
    "    for i in range(n_sim):\n",
    "        state, _ = env_copy.reset()\n",
    "        reward_sum = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.get_action(state, 0)\n",
    "            state, reward, terminated, truncated, _ = env_copy.step(action)\n",
    "            reward_sum += reward\n",
    "            done = terminated or truncated\n",
    "        episode_rewards[i] = reward_sum\n",
    "    return episode_rewards\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, reward, terminated, next_state):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = (state, action, reward, terminated, next_state)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.choices(self.memory, k=batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic neural net.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return self.net(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class DQN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        action_space,\n",
    "        observation_space,\n",
    "        gamma,\n",
    "        batch_size,\n",
    "        buffer_capacity,\n",
    "        update_target_every,\n",
    "        epsilon_start,\n",
    "        decrease_epsilon_factor,\n",
    "        epsilon_min,\n",
    "        learning_rate,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.action_space = action_space\n",
    "        self.observation_space = observation_space\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.update_target_every = update_target_every\n",
    "\n",
    "        self.epsilon_start = epsilon_start\n",
    "        self.decrease_epsilon_factor = (\n",
    "            decrease_epsilon_factor  # larger -> more exploration\n",
    "        )\n",
    "        self.epsilon_min = epsilon_min\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def update(self, state, action, reward, terminated, next_state):\n",
    "        # Convert numpy arrays or lists to tensors and ensure they are floats\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        action_tensor = torch.tensor([[action]], dtype=torch.int64)\n",
    "        reward_tensor = torch.tensor([reward], dtype=torch.float32)\n",
    "        terminated_tensor = torch.tensor([terminated], dtype=torch.int64)\n",
    "        next_state_tensor = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Store transition in the replay buffer\n",
    "        self.buffer.push(\n",
    "            state_tensor,\n",
    "            action_tensor,\n",
    "            reward_tensor,\n",
    "            terminated_tensor,\n",
    "            next_state_tensor,\n",
    "        )\n",
    "\n",
    "        # # add data to replay buffer\n",
    "        # self.buffer.push(\n",
    "        #     torch.tensor(state).unsqueeze(0),\n",
    "        #     torch.tensor([[action]], dtype=torch.int64),\n",
    "        #     torch.tensor([reward]),\n",
    "        #     torch.tensor([terminated], dtype=torch.int64),\n",
    "        #     torch.tensor(next_state, dtype=torch.float).unsqueeze(0),\n",
    "        # )\n",
    "\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return np.inf\n",
    "\n",
    "        # get batch\n",
    "        transitions = self.buffer.sample(self.batch_size)\n",
    "\n",
    "        state_batch, action_batch, reward_batch, terminated_batch, next_state_batch = (\n",
    "            tuple([torch.cat(data) for data in zip(*transitions)])\n",
    "        )\n",
    "\n",
    "        values = self.q_net.forward(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute the ideal Q values\n",
    "        with torch.no_grad():\n",
    "            next_state_values = (1 - terminated_batch) * self.target_net(\n",
    "                next_state_batch\n",
    "            ).max(1)[0]\n",
    "            targets = next_state_values * self.gamma + reward_batch\n",
    "\n",
    "        loss = self.loss_function(values, targets.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model with gradient clipping\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.q_net.parameters(), 1)  # Gradient clipping\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Soft update the target network\n",
    "        for target_param, local_param in zip(\n",
    "            self.target_net.parameters(), self.q_net.parameters()\n",
    "        ):\n",
    "            target_param.data.copy_(\n",
    "                0.995 * target_param.data + 0.005 * local_param.data\n",
    "            )\n",
    "\n",
    "        self.scheduler.step()  # Step through the scheduler\n",
    "\n",
    "        if not ((self.n_steps + 1) % self.update_target_every):\n",
    "            self.target_net.load_state_dict(self.q_net.state_dict())\n",
    "\n",
    "        self.decrease_epsilon()\n",
    "\n",
    "        self.n_steps += 1\n",
    "        if terminated:\n",
    "            self.n_eps += 1\n",
    "\n",
    "        return loss.detach().numpy()\n",
    "\n",
    "    def get_action(self, state, epsilon=None):\n",
    "        \"\"\"\n",
    "        Return action according to an epsilon-greedy exploration policy\n",
    "        \"\"\"\n",
    "        if epsilon is None:\n",
    "            epsilon = self.epsilon\n",
    "\n",
    "        if np.random.rand() < epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            return np.argmax(self.get_q(state))\n",
    "\n",
    "    def get_q(self, state):\n",
    "        \"\"\"\n",
    "        Compute Q function for a states\n",
    "        \"\"\"\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = self.q_net.forward(state_tensor)  # shape (1,  n_actions)\n",
    "        return output.numpy()[0]  # shape  (n_actions)\n",
    "\n",
    "    def decrease_epsilon(self):\n",
    "        self.epsilon = self.epsilon_min + (self.epsilon_start - self.epsilon_min) * (\n",
    "            np.exp(-1.0 * self.n_eps / self.decrease_epsilon_factor)\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        hidden_size = 256\n",
    "\n",
    "        # obs_size = self.observation_space.shape[0]\n",
    "        obs_size = np.prod(self.env.observation_space.shape)\n",
    "        n_actions = self.action_space.n\n",
    "\n",
    "        self.buffer = ReplayBuffer(self.buffer_capacity)\n",
    "        self.q_net = Net(obs_size, hidden_size, n_actions)\n",
    "        self.target_net = Net(obs_size, hidden_size, n_actions)\n",
    "        self.target_net.load_state_dict(\n",
    "            self.q_net.state_dict()\n",
    "        )  # Initialize target net\n",
    "        self.target_net.eval()  # Set target net to eval mode\n",
    "\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(\n",
    "            params=self.q_net.parameters(), lr=self.learning_rate, weight_decay=1e-5\n",
    "        )\n",
    "        self.scheduler = StepLR(\n",
    "            self.optimizer, step_size=100, gamma=0.99\n",
    "        )  # Learning rate scheduler\n",
    "\n",
    "        self.epsilon = self.epsilon_start\n",
    "        self.n_steps = 0\n",
    "        self.n_eps = 0\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"\n",
    "        Save the current model parameters to the specified file.\n",
    "        \"\"\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"q_net_state_dict\": self.q_net.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": self.scheduler.state_dict(),\n",
    "                \"epsilon\": self.epsilon,\n",
    "                \"n_steps\": self.n_steps,\n",
    "                \"n_eps\": self.n_eps,\n",
    "            },\n",
    "            filename,\n",
    "        )\n",
    "        print(f\"Model saved to {filename}\")\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\"\n",
    "        Load model parameters from the specified file.\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.q_net.load_state_dict(checkpoint[\"q_net_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        self.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        self.epsilon = checkpoint[\"epsilon\"]\n",
    "        self.n_steps = checkpoint[\"n_steps\"]\n",
    "        self.n_eps = checkpoint[\"n_eps\"]\n",
    "        self.target_net.load_state_dict(self.q_net.state_dict())\n",
    "        print(f\"Model loaded from {filename}\")\n",
    "\n",
    "\n",
    "def run_one_episode(env, agent, display=True):\n",
    "    display_env = deepcopy(env)\n",
    "    done = False\n",
    "    state, _ = display_env.reset()\n",
    "\n",
    "    rewards = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.get_action(state, 0)\n",
    "        state, reward, done, _, _ = display_env.step(action)\n",
    "        rewards += reward\n",
    "        if display:\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow(display_env.render())\n",
    "            plt.show()\n",
    "    if display:\n",
    "        display_env.close()\n",
    "    print(f\"Episode length {rewards}\")\n",
    "\n",
    "\n",
    "def run_episodes_for_a_minute(env, agent, display=True):\n",
    "    start_time = time.time()\n",
    "    episodes = 0\n",
    "    total_rewards = 0\n",
    "\n",
    "    while time.time() - start_time < 10:  # Exécuter pendant environ une minute\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        episode_rewards = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.get_action(state, 0)\n",
    "            state, reward, done, _, _ = env.step(action)\n",
    "            episode_rewards += reward\n",
    "            if display:\n",
    "                # clear_output(wait=True)\n",
    "                # plt.imshow(env.render())\n",
    "                # plt.show()\n",
    "                env.render()\n",
    "\n",
    "        episodes += 1\n",
    "        total_rewards += episode_rewards\n",
    "        print(f\"Episode {episodes} reward: {episode_rewards}\")\n",
    "\n",
    "    print(f\"Nombre total d'épisodes exécutés en 1 minute : {episodes}\")\n",
    "    print(f\"Récompense moyenne sur les épisodes : {total_rewards / episodes}\")\n",
    "\n",
    "\n",
    "# env = env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "# agent = RandomAgent(env.observation_space, env.action_space)\n",
    "\n",
    "# # Exécuter la fonction pour des épisodes répétés pendant environ une minute\n",
    "# run_episodes_for_a_minute(env, agent)\n",
    "\n",
    "# # run_one_episode(env, agent, display=True)\n",
    "# print(f\"Average over 5 runs : {np.mean(eval_agent(agent, env))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, agent, N_episodes, eval_every=10, reward_threshold=300):\n",
    "    total_time = 0\n",
    "    state, _ = env.reset()\n",
    "    losses = []\n",
    "    for ep in range(N_episodes):\n",
    "        done = False\n",
    "        state, _ = env.reset()\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            loss_val = agent.update(state, action, reward, terminated, next_state)\n",
    "\n",
    "            state = next_state\n",
    "            losses.append(loss_val)\n",
    "\n",
    "            done = terminated or truncated\n",
    "            total_time += 1\n",
    "\n",
    "        if (ep + 1) % eval_every == 0:\n",
    "            rewards = eval_agent(agent, env)\n",
    "            print(\"episode =\", ep + 1, \", reward = \", np.mean(rewards))\n",
    "            if np.mean(rewards) >= reward_threshold:\n",
    "                break\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode = 10 , reward =  2.53125\n",
      "episode = 20 , reward =  0.5\n",
      "episode = 30 , reward =  0.96875\n",
      "episode = 40 , reward =  2.827494567796629\n",
      "episode = 50 , reward =  5.694979999999999\n",
      "episode = 60 , reward =  4.276712\n",
      "episode = 70 , reward =  3.7913620000000003\n",
      "episode = 80 , reward =  4.018807366851836\n",
      "episode = 90 , reward =  3.9015639999999996\n",
      "episode = 100 , reward =  4.7202\n",
      "episode = 110 , reward =  11.375\n",
      "episode = 120 , reward =  4.199612\n",
      "episode = 130 , reward =  2.2967612492561456\n",
      "episode = 140 , reward =  3.6108805073549894\n",
      "episode = 150 , reward =  2.8971671671631976\n",
      "episode = 160 , reward =  3.014294082092948\n",
      "episode = 170 , reward =  3.82304382462861\n",
      "episode = 180 , reward =  2.936282246278844\n",
      "episode = 190 , reward =  11.13125\n",
      "episode = 200 , reward =  8.65625\n",
      "episode = 210 , reward =  9.9375\n",
      "episode = 220 , reward =  11.375\n",
      "episode = 230 , reward =  8.625\n",
      "episode = 240 , reward =  7.90625\n",
      "episode = 250 , reward =  2.4729704104647405\n",
      "episode = 260 , reward =  9.59375\n",
      "episode = 270 , reward =  11.49375\n",
      "episode = 280 , reward =  10.9375\n",
      "episode = 290 , reward =  6.53125\n",
      "episode = 300 , reward =  1.996244567796629\n",
      "episode = 310 , reward =  8.1\n",
      "episode = 320 , reward =  11.375\n",
      "episode = 330 , reward =  10.21875\n",
      "episode = 340 , reward =  9.63125\n",
      "episode = 350 , reward =  6.9375\n",
      "episode = 360 , reward =  10.0625\n",
      "episode = 370 , reward =  9.45625\n",
      "episode = 380 , reward =  7.10625\n",
      "episode = 390 , reward =  8.26875\n",
      "episode = 400 , reward =  11.1125\n",
      "episode = 410 , reward =  9.99375\n",
      "episode = 420 , reward =  9.38125\n",
      "episode = 430 , reward =  7.46875\n",
      "episode = 440 , reward =  11.8125\n",
      "episode = 450 , reward =  10.9375\n",
      "episode = 460 , reward =  13.2375\n",
      "episode = 470 , reward =  8.5375\n",
      "episode = 480 , reward =  8.75625\n",
      "episode = 490 , reward =  10.0625\n",
      "episode = 500 , reward =  10.0625\n",
      "episode = 510 , reward =  11.2875\n",
      "episode = 520 , reward =  10.9375\n",
      "episode = 530 , reward =  9.21875\n",
      "episode = 540 , reward =  7.1\n",
      "episode = 550 , reward =  9.5\n",
      "episode = 560 , reward =  9.30625\n",
      "episode = 570 , reward =  10.9375\n",
      "episode = 580 , reward =  9.0\n",
      "episode = 590 , reward =  10.34375\n",
      "episode = 600 , reward =  7.1875\n",
      "episode = 610 , reward =  7.05625\n",
      "episode = 620 , reward =  9.5\n",
      "episode = 630 , reward =  13.81875\n",
      "episode = 640 , reward =  8.18125\n",
      "episode = 650 , reward =  8.6875\n",
      "episode = 660 , reward =  6.383106968515088\n",
      "episode = 670 , reward =  11.8125\n",
      "episode = 680 , reward =  12.25\n",
      "episode = 690 , reward =  9.5625\n",
      "episode = 700 , reward =  8.4375\n",
      "episode = 710 , reward =  10.9375\n",
      "episode = 720 , reward =  8.46875\n",
      "episode = 730 , reward =  10.5\n",
      "episode = 740 , reward =  9.8125\n",
      "episode = 750 , reward =  8.525\n",
      "episode = 760 , reward =  4.224594082092948\n",
      "episode = 770 , reward =  9.625\n",
      "episode = 780 , reward =  11.175\n",
      "episode = 790 , reward =  7.243344082092948\n",
      "episode = 800 , reward =  11.375\n",
      "episode = 810 , reward =  7.4375\n",
      "episode = 820 , reward =  8.9625\n",
      "episode = 830 , reward =  10.9375\n",
      "episode = 840 , reward =  10.0625\n",
      "episode = 850 , reward =  8.032228362218106\n",
      "episode = 860 , reward =  9.525\n",
      "episode = 870 , reward =  11.375\n",
      "episode = 880 , reward =  8.90625\n",
      "episode = 890 , reward =  11.7\n",
      "episode = 900 , reward =  12.375\n",
      "episode = 910 , reward =  9.9375\n",
      "episode = 920 , reward =  8.03125\n",
      "episode = 930 , reward =  6.69375\n",
      "episode = 940 , reward =  9.5\n",
      "episode = 950 , reward =  11.375\n",
      "episode = 960 , reward =  11.543251331911923\n",
      "episode = 970 , reward =  9.9375\n",
      "episode = 980 , reward =  11.8125\n",
      "episode = 990 , reward =  9.4\n",
      "episode = 1000 , reward =  9.15625\n",
      "Model saved to dqn_agent_modif_1000.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c79bf9d0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adjusted environment initialization for \"highway-fast-v0\"\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from config import config\n",
    "\n",
    "# Configure and create the environment\n",
    "env = gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\", config=config)\n",
    "action_space = env.action_space\n",
    "observation_space = env.observation_space\n",
    "\n",
    "# Update the DQN Agent initialization with the new action and observation spaces\n",
    "# Note: Ensure that observation dimensions are correctly handled within your DQN architecture.\n",
    "# This might require adjustments depending on how the \"OccupancyGrid\" observations are structured.\n",
    "\n",
    "# Hyperparameters might need adjustment based on the new environment dynamics.\n",
    "gamma = 0.99\n",
    "batch_size = 128\n",
    "buffer_capacity = 20_000\n",
    "update_target_every = 32\n",
    "epsilon_start = 0.9\n",
    "decrease_epsilon_factor = 1500\n",
    "epsilon_min = 0.01\n",
    "learning_rate = 1e-4\n",
    "\n",
    "hidden_size = 256\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# When you instantiate the DQN agent:\n",
    "agent = DQN(\n",
    "    env,\n",
    "    action_space,\n",
    "    observation_space,\n",
    "    gamma,\n",
    "    batch_size,\n",
    "    buffer_capacity,\n",
    "    update_target_every,\n",
    "    epsilon_start,\n",
    "    decrease_epsilon_factor,\n",
    "    epsilon_min,\n",
    "    learning_rate,\n",
    ")\n",
    "\n",
    "# Training might need adjustments, especially evaluation metrics and thresholding for success.\n",
    "N_episodes = 1000\n",
    "\n",
    "# Proceed with the adjusted training function\n",
    "# Ensure that your training and evaluation routines properly handle the updated environment observations and actions.\n",
    "losses = train(env, agent, N_episodes)\n",
    "agent.save(\"dqn_agent_modif_1000.pth\")\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32), {'speed': 25, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 1.0, 'high_speed_reward': 0.5, 'on_road_reward': 1.0}})\n",
      "Model loaded from dqn_agent_3000.pth\n"
     ]
    }
   ],
   "source": [
    "# Load the trained agent\n",
    "from config import config\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "env = gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\", config=config)\n",
    "action_space = env.action_space\n",
    "observation_space = env.observation_space\n",
    "\n",
    "# Update the DQN Agent initialization with the new action and observation spaces\n",
    "# Note: Ensure that observation dimensions are correctly handled within your DQN architecture.\n",
    "# This might require adjustments depending on how the \"OccupancyGrid\" observations are structured.\n",
    "\n",
    "# Hyperparameters might need adjustment based on the new environment dynamics.\n",
    "gamma = 0.99\n",
    "batch_size = 128\n",
    "buffer_capacity = 20_000\n",
    "update_target_every = 32\n",
    "epsilon_start = 0.9\n",
    "decrease_epsilon_factor = 1500\n",
    "epsilon_min = 0.01\n",
    "learning_rate = 1e-4\n",
    "\n",
    "hidden_size = 256\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# When you instantiate the DQN agent:\n",
    "agent = DQN(\n",
    "    env,\n",
    "    action_space,\n",
    "    observation_space,\n",
    "    gamma,\n",
    "    batch_size,\n",
    "    buffer_capacity,\n",
    "    update_target_every,\n",
    "    epsilon_start,\n",
    "    decrease_epsilon_factor,\n",
    "    epsilon_min,\n",
    "    learning_rate,\n",
    ")\n",
    "\n",
    "agent.load(\"dqn_agent_3000.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean reward after training =  10.75625\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final policy\n",
    "rewards = eval_agent(agent, env, 50)\n",
    "print(\"\")\n",
    "print(\"mean reward after training = \", np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 19:12:52.290 Python[97197:1330509] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# env = gym.make('highway-v0', render_mode='rgb_array')\n",
    "state = env.reset()\n",
    "for _ in range(1):\n",
    "    state = env.reset()\n",
    "    # action = env.action_type.actions_indexes[\"IDLE\"]\n",
    "    # print(state)\n",
    "    action = agent.get_action(state)\n",
    "    # print(action)\n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "plt.imshow(env.render())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 7 at dim 1 (got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (done \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[0;32m----> 5\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m      7\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n",
      "Cell \u001b[0;32mIn[1], line 209\u001b[0m, in \u001b[0;36mDQN.get_action\u001b[0;34m(self, state, epsilon)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[1], line 215\u001b[0m, in \u001b[0;36mDQN.get_q\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_q\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m    212\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    Compute Q function for a states\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    217\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net\u001b[38;5;241m.\u001b[39mforward(state_tensor)  \u001b[38;5;66;03m# shape (1,  n_actions)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 7 at dim 1 (got 4)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    done = truncated = False\n",
    "    obs = env.reset()\n",
    "    while not (done or truncated):\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
